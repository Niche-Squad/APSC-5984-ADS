{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APSC-5984 Lab 6: Tidy data\n",
    "\n",
    "Due: 2023-03-13 (Monday) 23:59:59\n",
    "\n",
    "Grading Rubric (Total 300 points)\n",
    "\n",
    "| Items | Points | Earned |\n",
    "| :--- | :----- | :----- |\n",
    "| Push the assignment in time with the commit message: \"lab 6 submission\" | 210 | |\n",
    "| Tasks 1| 5 | |\n",
    "| Tasks 2| 5 | |\n",
    "| Tasks 3| 10 | |\n",
    "| Tasks 4| 15 | |\n",
    "| Tasks 5| 15 | |\n",
    "| Tasks 6| 5 | |\n",
    "| Tasks 7| 15 | |\n",
    "| Tasks 8| 5 | |\n",
    "| Tasks 9| 15 | |\n",
    "\n",
    "\n",
    "In this lab, you will reproduce the data analysis as shown in the tidy data paper but alter the `hod` factor to `sex` to discover any `cod` associated with gender."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Load the libraries accordingly (check the lecture slide if you are not sure how to do it):\n",
    "- `pandas`: alias `pd`\n",
    "- `numpy`: alias `np`\n",
    "- `plotnine`: from `plotnine` load all functions (*)\n",
    "- `statsmodels`: load `statsmodels.api` and alias it as `sm`\n",
    "\n",
    "If the import fails, install the library using:\n",
    "\n",
    "`conda install <library name>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import statsmodels.api as sm\n",
    "\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Load the data `tidy_X.csv` and check the first 5 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sex  age   yod  mod  dod  hod  cod\n",
      "0         1   90  2008    1    7   20  F17\n",
      "1         1   72  2008    1   13   14  I05\n",
      "2         1   49  2008    1   12   20  K65\n",
      "3         2   79  2008    1   20   10  I38\n",
      "4         1   15  2008    1    1   15  N18\n",
      "...     ...  ...   ...  ...  ...  ...  ...\n",
      "528323    1    1  2008   10    6   12  P22\n",
      "528324    2   20  2008   10   18   20  Q24\n",
      "528325    2    3  2008   11   11   19  P22\n",
      "528326    1   24  2008    9   25   12  P22\n",
      "528327    1    2  2008    9   22   16  P26\n",
      "\n",
      "[528328 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"data\"\n",
    "filename = r'/home/shihong/APSC-5984-ADS/labs/lab_06/data/tidy_X.csv'\n",
    "file_path = os.path.join(directory, filename)\n",
    "\n",
    "tidy_X = pd.read_csv(file_path)\n",
    "tidy_X.head()\n",
    "print(tidy_X)\n",
    "pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Groupping the data by `sex` and `cod`, and then calculate the frequency (size) of each group. Store the result in a variable called `data_grp`.\n",
    "\n",
    "Hints:\n",
    "- `df.groupby()`\n",
    "- `<pd.group>.agg()`\n",
    "- `df.reset_index()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex  cod  freq\n",
      "0       1  A01    27\n",
      "1       1  A02    23\n",
      "2       1  A03     3\n",
      "3       1  A04    68\n",
      "4       1  A05    12\n",
      "...   ...  ...   ...\n",
      "2067    2  Y83    93\n",
      "2068    2  Y84     8\n",
      "2069    2  Y86   182\n",
      "2070    2  Y87     1\n",
      "2071    2  Y89    17\n",
      "\n",
      "[2072 rows x 3 columns]\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "data_grp = tidy_X.groupby(['sex', 'cod']).size().reset_index(name='freq')\n",
    "print(data_grp)\n",
    "\n",
    "if 'freq' in data_grp:\n",
    "    print(\"ok\")\n",
    "else:\n",
    "    print(\"NO\")\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Calculate the gender proportion of deaths in each `cod`. Store the result in a variable called `prop_by_sexcod`.\n",
    "\n",
    "Hints:\n",
    "- `df.groupby()`\n",
    "- `<pd.group>.agg()`\n",
    "- `df.reset_index()`\n",
    "- `df.merge()`\n",
    "- The result dataframe, `data_grp`, should have five columns: `sex`, `cod`, `freq_by_sexcod`, `sum_by_cod`, and `prop_by_sexcod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['sum_by_cod'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sum_by_cod \u001b[39m=\u001b[39m data_grp\u001b[39m.\u001b[39;49mgroupby([\u001b[39m'\u001b[39;49m\u001b[39mcod\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfreq\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39;49magg({\u001b[39m\"\u001b[39;49m\u001b[39msum_by_cod\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[1;32m      2\u001b[0m data_grp \u001b[39m=\u001b[39m data_grp\u001b[39m.\u001b[39mmerge(sum_by_cod, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcod\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m data_grp[\u001b[39m'\u001b[39m\u001b[39mprop_by_sexcod\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data_grp[\u001b[39m'\u001b[39m\u001b[39mfreq\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m data_grp[\u001b[39m'\u001b[39m\u001b[39msum_by_cod\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/groupby/generic.py:894\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    893\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 894\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[1;32m    895\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:169\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[1;32m    170\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    171\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:478\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m     selected_obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selected_obj\n\u001b[1;32m    476\u001b[0m     selection \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selection\n\u001b[0;32m--> 478\u001b[0m arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m, selected_obj, arg)\n\u001b[1;32m    480\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    481\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     colg \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_gotitem(selection, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/apply.py:601\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m         cols_sorted \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(safe_sort(\u001b[39mlist\u001b[39m(cols)))\n\u001b[0;32m--> 601\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00mcols_sorted\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    603\u001b[0m aggregator_types \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['sum_by_cod'] do not exist\""
     ]
    }
   ],
   "source": [
    "sum_by_cod = data_grp.groupby(['cod', 'freq']).agg({\"sum_by_cod\": \"sum\"})\n",
    "data_grp = data_grp.merge(sum_by_cod, on='cod')\n",
    "data_grp['prop_by_sexcod'] = data_grp['freq'] / data_grp['sum_by_cod']\n",
    "data_grp = data_grp[['sex', 'cod', 'freq', 'sum_by_cod', 'prop_by_sexcod']]\n",
    "\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "Calculate the proportion of deaths by `sex` regardless of `cod`. Store the result in a variable called `prop_by_sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Calculate the difference between `prop_by_sexcod` and `prop_by_sex` using the formula:\n",
    "\n",
    "diff_prop = (prop_by_sexcod - prop_by_sex) ** 2\n",
    "\n",
    "And store the result as a new column in `data_grp` called `diff_prop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "Derive a dataframe called `devi` that contains the `n` and `dist` columns from `data_grp`. And remove any rows that have `n` less than 50. Please use the lecture slide as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "Use log-scale to plot the `dist` vs `n` using `geom_point()` and `geom_smooth(method=\"lm\")`. Please use the lecture slide as a reference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "Use a linear model to fit the data and derive residuals. Then store the residuals in a variable called `resid` in the dataframe `devi`.\n",
    "\n",
    "IMPORTANT: Apply the log transformation to both `n` and `dist` before fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "The assignment is done. You are encouraged to run the following code to check your results. You DO NOT need to modify anything below this line.\n",
    "\n",
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(devi, aes(x = 'log_n', y = 'resid')) + geom_point() +geom_hline(yintercept = 4, color = \"red\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to add the full names of `cod` and `resid` to `data_grp`\n",
    "(YOU DO NOT NEED TO MODIFY ANYTHING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cod = pd.read_csv(\"data/tidy_X_map_cod.csv\")\n",
    "map_cod.columns = [\"cod\", \"cod_name\"]\n",
    "devi2 = pd.merge(devi, map_cod).drop_duplicates()\n",
    "devi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_grp2 = pd.merge(data_grp, devi2, on=\"cod\")\n",
    "data_grp2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the outliers that have residuals greater than 4. (YOU DO NOT NEED TO MODIFY ANYTHING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vis = data_grp2.query(\"resid > 4\")\n",
    "print(data_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(data_vis, aes(x = 'factor(sex)', y = 'prop_by_sexcod')) +\\\n",
    "    geom_point(aes(y = \"prop_by_sex\"), colour = \"grey\") +\\\n",
    "    geom_point() +\\\n",
    "    facet_wrap('~cod_name', ncol = 3) +\\\n",
    "    theme(figure_size=(16, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "niche",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad532947ed7ac808c0a842d8ff1aa280c18aa45f795e2b1f2d64f29153af8175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
